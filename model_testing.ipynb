{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory before:  /dtu/blackhole/1d/155421/Deeplearning-Group16\n",
      "Current working directory:  /dtu/blackhole/1d/155421/Deeplearning-Group16\n"
     ]
    }
   ],
   "source": [
    "# Create a dataset from directories cars_fake and cars_real\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "\n",
    "# Create a dataset from directories cars_fake and cars_real\n",
    "data_dirs = ['../cars_dataset/cars/1_fake', '../cars_dataset/cars/0_real']\n",
    "\n",
    "print(\"Current working directory before: \", os.getcwd())\n",
    "proj_dir = \"/dtu/blackhole/1d/155421/Deeplearning-Group16\"\n",
    "# Set the current working directory to the project directory\n",
    "os.chdir(proj_dir)\n",
    "print(\"Current working directory: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch\n",
    "\n",
    "from resnet50nodown import resnet50nodown\n",
    "\n",
    "class DIMD(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DIMD, self).__init__()\n",
    "        self.model = resnet50nodown(num_classes=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def load_weights(self, ckpt):\n",
    "        state_dict = torch.load(ckpt, map_location='cpu')\n",
    "        try:\n",
    "            self.model.load_state_dict(state_dict['model'])\n",
    "            if ('module._conv_stem.weight' in state_dict['model']) or ('module.fc.fc1.weight' in state_dict['model']) or ('module.fc.weight' in state_dict['model']):\n",
    "                self.load_state_dict({key[7:]: state_dict['model'][key] for key in state_dict['model']})\n",
    "            else:\n",
    "                self.model.load_state_dict(state_dict['model'])\n",
    "\n",
    "        except:\n",
    "            print('Loading state dict failed. Trying to load without model prefix.')\n",
    "            self.model.load_state_dict(state_dict)\n",
    "\n",
    "    def predict(self, img):\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(img)\n",
    "            return logits.sigmoid().flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip \n",
    "import torch.nn as nn \n",
    "import torch\n",
    "\n",
    "class UnivFD(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(UnivFD, self).__init__()\n",
    "        self.model, self.preprocess = clip.load(\"ViT-L/14\", device=\"cpu\")\n",
    "        self.fc = nn.Linear(768, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.model.encode_image(x) \n",
    "        return self.fc(features)\n",
    "    \n",
    "    def load_weights(self, ckpt):\n",
    "        state_dict = torch.load(ckpt, map_location='cpu')\n",
    "        self.fc.load_state_dict(state_dict)\n",
    "\n",
    "    def predict(self, img):\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(img)\n",
    "            return logits.sigmoid().flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch\n",
    "\n",
    "from resnet_npr import resnet50\n",
    "\n",
    "class NPR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NPR, self).__init__()\n",
    "        self.model = resnet50(num_classes=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def load_weights(self, ckpt):\n",
    "        state_dict = torch.load(ckpt, map_location='cpu')\n",
    "        try:\n",
    "            self.model.load_state_dict(state_dict['model'], strict=False)\n",
    "        except:\n",
    "            print('Loading failed, trying to load model without module')\n",
    "            self.model.load_state_dict(state_dict)\n",
    "\n",
    "    def predict(self, img):\n",
    "        with torch.no_grad():\n",
    "            return self.forward(img).sigmoid().flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_964832/2975036983.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(ckpt, map_location='cpu')\n",
      "/tmp/ipykernel_964832/2004797838.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(ckpt, map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DIMD_model = DIMD().to(device)\n",
    "DIMD_model.load_weights('../DIMD_latent_weights/model_epoch_best.pth')\n",
    "\n",
    "UnivFD_model = UnivFD().to(device)\n",
    "UnivFD_model.load_weights('../UnivFD_weights/fc_weights.pth')\n",
    "\n",
    "NPR_model = NPR().to(device)\n",
    "NPR_model.load_weights('../NPR_weights/NPR.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fake image:  [0.14770643413066864]\n",
      "Prediction for real image:  [0.08515327423810959]\n"
     ]
    }
   ],
   "source": [
    "model_to_test = DIMD_model\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_to_test = model_to_test.to(device)\n",
    "\n",
    "def predict_image(image_path, model):\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Resize the image\n",
    "    #img = img.resize((224, 224))\n",
    "    \n",
    "    # Display the image\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "    \n",
    "    # Convert the image to a tensor and move it to the same device as the model\n",
    "    img_tensor = transforms.ToTensor()(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Make prediction\n",
    "    result = model.predict(img_tensor)\n",
    "    return result\n",
    "\n",
    "# Predict on single images\n",
    "img_path = \"cars_fake/Acura Integra Type R 2001/4.png\"\n",
    "img_path_2 = \"cars_real/Acura Integra Type R 2001/00198.jpg\"\n",
    "\n",
    "result = predict_image(img_path, model_to_test)\n",
    "result2 = predict_image(img_path_2, model_to_test)\n",
    "\n",
    "print(\"Prediction for fake image: \", result)\n",
    "print(\"Prediction for real image: \", result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 images\n",
      "Max dimensions: (2560, 1698)\n",
      "Min dimensions: (220, 152)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def crawl_directories_and_get_image_sizes(directory):\n",
    "    results = []\n",
    "    max_size = (0, 0)  # Initialize max dimensions as (width, height)\n",
    "    min_size = (float('inf'), float('inf'))  # Initialize min dimensions as (width, height)\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".png\") or file.endswith(\".jpg\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                results.append(file_path)\n",
    "\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        width, height = img.size\n",
    "\n",
    "                        # Update max size\n",
    "                        if (width * height) > (max_size[0] * max_size[1]):\n",
    "                            max_size = (width, height)\n",
    "\n",
    "                        # Update min size\n",
    "                        if (width * height) < (min_size[0] * min_size[1]):\n",
    "                            min_size = (width, height)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image {file_path}: {e}\")\n",
    "\n",
    "    return results, max_size, min_size\n",
    "\n",
    "# Example usage\n",
    "directory = \"cars_real\"  # Replace with your directory path\n",
    "image_paths, max_dimensions, min_dimensions = crawl_directories_and_get_image_sizes(directory)\n",
    "print(f\"Found {len(image_paths)} images\")\n",
    "print(f\"Max dimensions: {max_dimensions}\")\n",
    "print(f\"Min dimensions: {min_dimensions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_dl16_mpi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
